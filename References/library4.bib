@article{Ciullo2021,
  title = {A Framework for Building Climate Storylines Based on Downward Counterfactuals: {{The}} Case of the {{European Union Solidarity}} Fund},
  author = {Ciullo, Alessio and Martius, Olivia and Strobl, Eric and Bresch, David N.},
  date = {2021-01-01},
  journaltitle = {Climate Risk Management},
  shortjournal = {Climate Risk Management},
  volume = {33},
  pages = {100349},
  issn = {2212-0963},
  doi = {10.1016/j.crm.2021.100349},
  url = {https://www.sciencedirect.com/science/article/pii/S2212096321000784},
  abstract = {Recent research introduced the concept of climate storylines as an alternative approach to estimate climate impact and better deal with uncertainties. A climate storyline is an event-based approach which aims at building “physically self-consistent unfolding of past events, or of plausible future events or pathways”. As such, climate storylines may profit from downward counterfactual thinking, which aims at analyzing how past events could have been worse. Notwithstanding the various applications of downward counterfactual thinking in the natural risk management literature, no study relates this with the climate storyline approach. The main goal of this paper is thus to introduce a framework that supports the development of climate storylines from downward counterfactuals. The framework is event-oriented, it focuses on impact, and it is designed to be applied in a participatory fashion. As a proof-of-concept application, we study the impact of tropical cyclones on the European Union Solidarity Fund (EUSF) without conducting a participatory analysis. Tropical cyclones represent a serious threat for the European outermost regions, and their impact to the EUSF capital availability has never been studied. We find that payouts due to tropical cyclones can hamper a recovery of the fund if large payouts concurrently occur in mainland Europe. To avoid this also considering future changes, an increase in capitalization up to 90 \% percent may be required.},
  keywords = {Climate storylines,Downward counterfactuals,European Union Solidarity Fund}
}

@inproceedings{Cowell2001,
  title = {Conditions under Which Conditional Independence and Scoring Methods Lead to Identical Selection of Bayesian Network Models},
  booktitle = {Proceedings of the 17th {{Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Cowell, Robert G.},
  date = {2001},
  pages = {91--97},
  doi = {10.48550/arXiv.1301.2262},
  url = {https://arxiv.org/abs/1301.2262}
}

@article{Hazeleger2015,
  title = {Tales of Future Weather},
  author = {Hazeleger, Wilco and Hurk, Bart and Min, Erik and Van Oldenborgh, Geert Jan and Petersen, Arthur and Stainforth, David and Vasileiadou, Eleftheria and Smith, Leonard},
  date = {2015-01-28},
  journaltitle = {Nature Climate Change},
  shortjournal = {Nature Climate Change},
  volume = {5},
  pages = {107--113},
  doi = {10.1038/nclimate2450},
  abstract = {Society is vulnerable to extreme weather events and, by extension, to human impacts on future events. As climate changes weather patterns will change. The search is on for more effective methodologies to aid decision-makers both in mitigation to avoid climate change and in adaptation to changes. The traditional approach uses ensembles of climate model simulations, statistical bias correction, downscaling to the spatial and temporal scales relevant to decision-makers, and then translation into quantities of interest. The veracity of this approach cannot be tested, and it faces in-principle challenges. Alternatively, numerical weather prediction models in a hypothetical climate setting can provide tailored narratives of high-resolution simulations of high-impact weather in a future climate. This ‘tales of future weather’ approach will aid in the interpretation of lower-resolution simulations. Arguably, it potentially provides complementary, more realistic and more physically consistent pictures of what future weather might look like.}
}

@article{Hoerling2013,
  title = {Anatomy of an {{Extreme Event}}},
  author = {Hoerling, Martin and Kumar, Arun and Dole, Randall and Nielsen-Gammon, John W. and Eischeid, Jon and Perlwitz, Judith and Quan, Xiao-Wei and Zhang, Tao and Pegion, Philip and Chen, Mingyue},
  date = {2013},
  journaltitle = {Journal of Climate},
  volume = {26},
  number = {9},
  pages = {2811--2832},
  doi = {10.1175/JCLI-D-12-00270.1},
  url = {https://journals.ametsoc.org/view/journals/clim/26/9/jcli-d-12-00270.1.xml}
}

@article{Matthews2016,
  title = {Past and Future Climate Change in the Context of Memorable Seasonal Extremes},
  author = {Matthews, T. and Mullan, D. and Wilby, R.L. and Broderick, C. and Murphy, C.},
  date = {2016-01-01},
  journaltitle = {Climate Risk Management},
  shortjournal = {Climate Risk Management},
  volume = {11},
  pages = {37--52},
  issn = {2212-0963},
  doi = {10.1016/j.crm.2016.01.004},
  url = {https://www.sciencedirect.com/science/article/pii/S221209631600005X},
  abstract = {It is thought that direct personal experience of extreme weather events could result in greater public engagement and policy response to climate change. Based on this premise, we present a set of future climate scenarios for Ireland communicated in the context of recent, observed extremes. Specifically, we examine the changing likelihood of extreme seasonal conditions in the long-term observational record, and explore how frequently such extremes might occur in a changed Irish climate according to the latest model projections. Over the period (1900–2014) records suggest a greater than 50-fold increase in the likelihood of the warmest recorded summer (1995), whilst the likelihood of the wettest winter (1994/95) and driest summer (1995) has respectively doubled since 1850. The most severe end-of-century climate model projections suggest that summers as cool as 1995 may only occur once every ∼7years, whilst winters as wet as 1994/95 and summers as dry as 1995 may increase by factors of ∼8 and ∼10 respectively. Contrary to previous research, we find no evidence for increased wintertime storminess as the Irish climate warms, but caution that this conclusion may be an artefact of the metric employed. It is hoped that framing future climate scenarios in the context of extremes from living memory will help communicate the scale of the challenge climate change presents, and in so doing bridge the gap between climate scientists and wider society.},
  keywords = {Climate change communication,CMIP5,Extreme seasonal weather,Irish climate change projections,North Atlantic storminess,Seasonal analogues}
}

@book{Natori2017,
  title = {Consistent {{Learning Bayesian Networks}} with {{Thousands}} of {{Variables}}},
  author = {Natori, Kazuki and Uto, Masaki and Ueno, Maomi},
  date = {2017-09-20}
}

@unpublished{Scutari2019,
  title = {Challenges in {{Bayesian Network Modelling}} of {{Climate}} and {{Weather Data}}},
  author = {Scutari, Marco},
  date = {2019-11-06},
  eventtitle = {1st “{{Artificial Intelligence}} for {{Copernicus}}” {{Workshop}}},
  langid = {english},
  venue = {Reading, UK}
}

@article{Scutari2019a,
  title = {Learning {{Bayesian}} Networks from Big Data with Greedy Search: Computational Complexity and Efficient Implementation},
  author = {Scutari, Marco and Vitolo, Claudia and Tucker, Allan},
  date = {2019-09-01},
  journaltitle = {Statistics and Computing},
  shortjournal = {Statistics and Computing},
  volume = {29},
  number = {5},
  pages = {1095--1108},
  issn = {1573-1375},
  doi = {10.1007/s11222-019-09857-1},
  url = {https://doi.org/10.1007/s11222-019-09857-1},
  abstract = {Learning the structure of Bayesian networks from data is known to be a computationally challenging, NP-hard problem. The literature has long investigated how to perform structure learning from data containing large numbers of variables, following a general interest in high-dimensional applications (“small n, large p”) in systems biology and genetics. More recently, data sets with large numbers of observations (the so-called “big data”) have become increasingly common; and these data sets are not necessarily high-dimensional, sometimes having only a few tens of variables depending on the application. We revisit the computational complexity of Bayesian network structure learning in this setting, showing that the common choice of measuring it with the number of estimated local distributions leads to unrealistic time complexity estimates for the most common class of score-based algorithms, greedy search. We then derive more accurate expressions under common distributional assumptions. These expressions suggest that the speed of Bayesian network learning can be improved by taking advantage of the availability of closed-form estimators for local distributions with few parents. Furthermore, we find that using predictive instead of in-sample goodness-of-fit scores improves speed; and we confirm that it improves the accuracy of network reconstruction as well, as previously observed by Chickering and Heckerman (Stat Comput 10: 55–62,~2000). We demonstrate these results on large real-world environmental and epidemiological data; and on reference data sets available from public repositories.}
}

@article{Scutari2019b,
  title = {Who Learns Better {{Bayesian}} Network Structures: {{Accuracy}} and Speed of Structure Learning Algorithms},
  author = {Scutari, Marco and Graafland, Catharina Elisabeth and Gutiérrez, José Manuel},
  date = {2019-12-01},
  journaltitle = {International Journal of Approximate Reasoning},
  shortjournal = {International Journal of Approximate Reasoning},
  volume = {115},
  pages = {235--253},
  issn = {0888-613X},
  doi = {10.1016/j.ijar.2019.10.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0888613X19301434},
  abstract = {Three classes of algorithms to learn the structure of Bayesian networks from data are common in the literature: constraint-based algorithms, which use conditional independence tests to learn the dependence structure of the data; score-based algorithms, which use goodness-of-fit scores as objective functions to maximise; and hybrid algorithms that combine both approaches. Constraint-based and score-based algorithms have been shown to learn the same structures when conditional independence and goodness of fit are both assessed using entropy and the topological ordering of the network is known [1]. In this paper, we investigate how these three classes of algorithms perform outside the assumptions above in terms of speed and accuracy of network reconstruction for both discrete and Gaussian Bayesian networks. We approach this question by recognising that structure learning is defined by the combination of a statistical criterion and an algorithm that determines how the criterion is applied to the data. Removing the confounding effect of different choices for the statistical criterion, we find using both simulated and real-world complex data that constraint-based algorithms are often less accurate than score-based algorithms, but are seldom faster (even at large sample sizes); and that hybrid algorithms are neither faster nor more accurate than constraint-based algorithms. This suggests that commonly held beliefs on structure learning in the literature are strongly influenced by the choice of particular statistical criteria rather than just by the properties of the algorithms themselves.},
  keywords = {Bayesian networks,Climate networks,Conditional independence tests,Network scores,ObsCite,Structure learning}
}

@article{Shepherd2016,
  title = {A {{Common Framework}} for {{Approaches}} to {{Extreme Event Attribution}}},
  author = {Shepherd, Theodore G.},
  date = {2016-03-01},
  journaltitle = {Current Climate Change Reports},
  shortjournal = {Current Climate Change Reports},
  volume = {2},
  number = {1},
  pages = {28--38},
  issn = {2198-6061},
  doi = {10.1007/s40641-016-0033-y},
  url = {https://doi.org/10.1007/s40641-016-0033-y},
  abstract = {The extent to which a given extreme weather or climate event is attributable to anthropogenic climate change is a question of considerable public interest. From a scientific perspective, the question can be framed in various ways, and the answer depends very much on the framing. One such framing is a risk-based approach, which answers the question probabilistically, in terms of a change in likelihood of a class of event similar to the one in question, and natural variability is treated as noise. A rather different framing is a storyline approach, which examines the role of the various factors contributing to the event as it unfolded, including the anomalous aspects of natural variability, and answers the question deterministically. It is argued that these two apparently irreconcilable approaches can be viewed within a common framework, where the most useful level of conditioning will depend on the question being asked and the uncertainties involved.}
}

@article{Shepherd2018,
  title = {Storylines: An Alternative Approach to Representing Uncertainty in Physical Aspects of Climate Change},
  author = {Shepherd, Theodore G. and Boyd, Emily and Calel, Raphael A. and Chapman, Sandra C. and Dessai, Suraje and Dima-West, Ioana M. and Fowler, Hayley J. and James, Rachel and Maraun, Douglas and Martius, Olivia and Senior, Catherine A. and Sobel, Adam H. and Stainforth, David A. and Tett, Simon F. B. and Trenberth, Kevin E. and family=Hurk, given=Bart J. J. M., prefix=van den, useprefix=true and Watkins, Nicholas W. and Wilby, Robert L. and Zenghelis, Dimitri A.},
  date = {2018-12-01},
  journaltitle = {Climatic Change},
  shortjournal = {Climatic Change},
  volume = {151},
  number = {3},
  pages = {555--571},
  issn = {1573-1480},
  doi = {10.1007/s10584-018-2317-9},
  url = {https://doi.org/10.1007/s10584-018-2317-9},
  abstract = {As climate change research becomes increasingly applied, the need for actionable information is growing rapidly. A key aspect of this requirement is the representation of uncertainties. The conventional approach to representing uncertainty in physical aspects of climate change is probabilistic, based on ensembles of climate model simulations. In the face of deep uncertainties, the known limitations of this approach are becoming increasingly apparent. An alternative is thus emerging which may be called a ‘storyline’ approach. We define a storyline as a physically self-consistent unfolding of past events, or of plausible future events or pathways. No a priori probability of the storyline is assessed; emphasis is placed instead on understanding the driving factors involved, and the plausibility of those factors. We introduce a typology of four reasons for using storylines to represent uncertainty in physical aspects of climate change: (i) improving risk awareness by framing risk in an event-oriented rather than a probabilistic manner, which corresponds more directly to how people perceive and respond to risk; (ii) strengthening decision-making by allowing one to work backward from a particular vulnerability or decision point, combining climate change information with other relevant factors to address compound risk and develop appropriate stress tests; (iii) providing a physical basis for partitioning uncertainty, thereby allowing the use of more credible regional models in a conditioned manner and (iv) exploring the boundaries of plausibility, thereby guarding against false precision and surprise. Storylines also offer a powerful way of linking physical with human aspects of climate change.}
}

@article{Shepherd2019,
  title = {Storyline Approach to the Construction of Regional Climate Change Information},
  author = {Shepherd, Ted},
  date = {2019-05-15},
  journaltitle = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  shortjournal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {475},
  pages = {20190013},
  doi = {10.1098/rspa.2019.0013},
  abstract = {Climate science seeks to make statements of confidence about what has happened, and what will happen (conditional on scenario). The approach is effective for the global, thermodynamic aspects of climate change, but is ineffective when it comes to aspects of climate change related to atmospheric circulation, which are highly uncertain. Yet, atmospheric circulation strongly mediates climate impacts at the regional scale. In this way, the confidence framework, which focuses on avoiding type 1 errors (false alarms), raises the prospect of committing type 2 errors (missed warnings). This has ethical implications. At the regional scale, however, where information on climate change has to be combined with many other factors affecting vulnerability and exposure-most of which are highly uncertain-the societally relevant question is not 'What will happen?' but rather 'What is the impact of particular actions under an uncertain regional climate change?' This reframing of the question can cut the Gordian knot of regional climate change information, provided one distinguishes between epistemic and aleatoric uncertainties-something that is generally not done in climate projections. It is argued that the storyline approach to climate change-the identification of physically self-consistent, plausible pathways-has the potential to accomplish precisely this.}
}

@article{Vitolo2018,
  title = {Modeling {{Air Pollution}}, {{Climate}}, and {{Health Data Using Bayesian Networks}}: {{A Case Study}} of the {{English Regions}}},
  author = {Vitolo, Claudia and Scutari, Marco and Ghalaieny, Mohamed and Tucker, Allan and Russell, Andrew},
  date = {2018-04-01},
  journaltitle = {Earth and Space Science},
  shortjournal = {Earth and Space Science},
  volume = {5},
  number = {4},
  pages = {76--88},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/2017EA000326},
  url = {https://doi.org/10.1002/2017EA000326},
  urldate = {2024-10-19},
  abstract = {The link between pollution and health is commonly explored by trying to identify the dominant cause of pollution and its most significant effect on health outcomes. The use of multivariate features to describe exposure is less explored because investigating a large domain of scenarios is theoretically (i.e., interpretation of results) and technically (i.e., computational effort) challenging. In this work we explore the use of Bayesian Networks with a multivariate approach to identify the probabilistic dependence structure of the environment-health nexus. This consists of environmental factors (topography and climate), exposure levels (concentration of outdoor air pollutants), and health outcomes (mortality rates). The information is collated with regard to a data-rich study area: the English regions (UK), which incorporate environmental types that are different in character from urban to rural. We implemented a reproducible workflow in the R programming language to collate environment-health data and analyze almost 50 millions of observations making use of a graphical model (Bayesian Network) and Big Data technologies. Results show that for pollution and weather variables the model tests well in sample but also has good predictive power when tested out of sample. This is facilitated by a training/testing split in the data along time and space dimension and suggests that the model generalizes well to new regions and time periods.},
  keywords = {air pollution,Bayesian Networks,climate,health,modeling}
}

@incollection{Woo,
  title = {Stochastic {{Modeling}} of {{Possible Pasts}} to {{Illuminate Future Risk}}},
  booktitle = {The {{Oxford Handbook}} of {{Complex Disaster Risks}} and {{Resilience}}},
  author = {Woo, Gordon and Johnson, Neil F.},
  editor = {Shultz, James M. and Rechkemmer, Andreas},
  pages = {0},
  publisher = {Oxford University Press},
  url = {https://doi.org/10.1093/oxfordhb/9780190466145.013.12},
  urldate = {2024-09-04},
  abstract = {Disasters are fortunately uncommon events. Far more common are events that lead to societal crises, which are notable in their impact, but fall short of causing a disaster. Such near-miss events may be reimagined through stochastic modeling to be worse than they actually were. These are termed downward counterfactuals. A spectrum of reimagined events, covering both natural and man-made hazards, are considered. Included is a counterfactual version of the Middle East Respiratory Syndrome (MERS). Attention to this counterfactual coronavirus in 2015 would have prepared the world better for COVID-19.},
  isbn = {978-0-19-046614-5}
}

@article{Woo2020,
  title = {Inter-{{Comparisons}} of {{Daily Sea Surface Temperatures}} and {{In-Situ Temperatures}} in the {{Coastal Regions}}},
  author = {Woo, Hye-Jin and Park, Kyung-Ae},
  date = {2020},
  journaltitle = {Remote Sensing},
  volume = {12},
  number = {10},
  issn = {2072-4292},
  doi = {10.3390/rs12101592},
  url = {https://www.mdpi.com/2072-4292/12/10/1592},
  abstract = {In this study, seven, global, blended, sea surface temperature (SST) analyses, including Operational SST and Sea Ice Analysis (OSTIA), Canadian Meteorological Centre (CMC) analysis, Optimum Interpolation SST (OISST), Remote Sensing System (REMSS) analysis, Multi-scale Ultra-high Resolution SST (MURSST), Merged Satellite and In situ Data Global Daily SST (MGDSST), and Geo-Polar Blended SST (Blended SST) were conducted. In-situ temperature measurements were used for the years 2014–2018, from 35 narrowly-spaced buoys distributed along the Korean Peninsula coast, to investigate how well the SST analyses represent the temperatures at the coastal regions. Contrary to the overall accuracy of the SSTs in the global ocean and offshore regions, the root-mean-square errors for the analyses were relatively large over 1.27 K. Specifically, all SST analyses resulted in warm biases over 0.31 K, which became quite distinctive in the western and the southwestern coastal regions. Investigation of the errors identified relationships with the coastal zones of vigorous tidal mixing, shallow bathymetry, and absence of microwave measurements. Overall, temporal wavelet coherency between in-situ measurements and SST products revealed high coherency of greater than 0.8 in periods longer than 180 days, however, low coherency ({$<$}0.5) in the period shorter than 10 days was observed. Inter-comparisons between the SST analyses illustrated clear spatial differences in the correlations at both the coastal regions, along the southwestern coast of the Korean Peninsula and in the frontal regions, and in the marginal seas of the Northwest Pacific. Overall, the results emphasized on the importance of using real-time in-situ measurements as much as possible, to overcome the increasing SST errors in coastal regions.}
}
